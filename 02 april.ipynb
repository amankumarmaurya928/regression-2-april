{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5abc26-4cd6-409e-b679-ab1125fb452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid.\\n   It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting\\n   the best parameter values, predictions are made.\\n   use grid search CV for regression:\\nStep 1 - Import the library - GridSearchCv. ...\\nStep 2 - Setup the Data. ...\\nStep 3 - Model and its Parameter. ...\\nStep 4 - Using GridSearchCV and Printing Results.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid.\n",
    "   It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting\n",
    "   the best parameter values, predictions are made.\n",
    "   use grid search CV for regression:\n",
    "Step 1 - Import the library - GridSearchCv. ...\n",
    "Step 2 - Setup the Data. ...\n",
    "Step 3 - Model and its Parameter. ...\n",
    "Step 4 - Using GridSearchCV and Printing Results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ef2cdc-9a0e-4157-beed-59dc3ddd0d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"grid search looks at every possible combination of hyperparameters to find the best model,\\n   random search only selects and tests a random combination of hyperparameters. \\n   This technique randomly samples from a grid of hyperparameters instead of conducting an exhaustive search.\\n   \\n   GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid.\\n   It's essentially a cross-validation technique. The model as well as the parameters must be entered.\\n   \\n   the RandomizedSearchCV for random search and GridSearchCV for grid search. Both techniques evaluate models \\n   for a given hyperparameter vector using cross-validation, hence the “CV” suffix of each class name.\\n   \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''grid search looks at every possible combination of hyperparameters to find the best model,\n",
    "   random search only selects and tests a random combination of hyperparameters. \n",
    "   This technique randomly samples from a grid of hyperparameters instead of conducting an exhaustive search.\n",
    "   \n",
    "   GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid.\n",
    "   It's essentially a cross-validation technique. The model as well as the parameters must be entered.\n",
    "   \n",
    "   the RandomizedSearchCV for random search and GridSearchCV for grid search. Both techniques evaluate models \n",
    "   for a given hyperparameter vector using cross-validation, hence the “CV” suffix of each class name.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f63670-040e-4206-8f96-98e99ac4b22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data leakage (or leakage) happens when your training data contains information about the target, but similar data will\\n   not be available when the model is used for prediction. This leads to high performance on the training set\\n   (and possibly even the validation data), but the model will perform poorly in production.\\n    Data leakage is one of the major problems in machine learning which occurs when the data that we are using to train\\n    an ML algorithm has the information the model is trying to predict. It is a situation that causes unpredictable and \\n    bad prediction outcomes after model deployment.\\n    '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''Data leakage (or leakage) happens when your training data contains information about the target, but similar data will\n",
    "   not be available when the model is used for prediction. This leads to high performance on the training set\n",
    "   (and possibly even the validation data), but the model will perform poorly in production.\n",
    "    Data leakage is one of the major problems in machine learning which occurs when the data that we are using to train\n",
    "    an ML algorithm has the information the model is trying to predict. It is a situation that causes unpredictable and \n",
    "    bad prediction outcomes after model deployment.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0eb92f0-b8eb-4b7f-8195-7ddbafd7c858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One of the best ways to get rid of data leakage is to perform k-fold cross validation where the overall data is \\n   divided into k parts. After dividing into k parts, we use each part as the cross-validation data and the remaining as \\n   training data.\\n   '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''One of the best ways to get rid of data leakage is to perform k-fold cross validation where the overall data is \n",
    "   divided into k parts. After dividing into k parts, we use each part as the cross-validation data and the remaining as \n",
    "   training data.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293800da-6420-479c-8b08-8dbb6708f8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use\\n   the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent\\n   predicted classifications, while columns represent the true classes from the data.\\n   \\n  A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the\\n  total number of target classes. The matrix compares the actual target values with those predicted by the machine \\n  learning model.\\n  A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect\\n  predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\\n  '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use\n",
    "   the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent\n",
    "   predicted classifications, while columns represent the true classes from the data.\n",
    "   \n",
    "  A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the\n",
    "  total number of target classes. The matrix compares the actual target values with those predicted by the machine \n",
    "  learning model.\n",
    "  A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect\n",
    "  predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d9dc35-4673-42fa-b9be-7f7b3411100c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances,\\n             Precision = TP /(TP+FP)\\n   while recall (also known as sensitivity) is the fraction of relevant instances that were retrieved. Both precision \\n   and recall are therefore based on relevance.\\n             Recall = TP/(TP+FN)\\n   \\nwhere, TP is true positive, FP is false positive, FN is false negative.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''Precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances,\n",
    "             Precision = TP /(TP+FP)\n",
    "   while recall (also known as sensitivity) is the fraction of relevant instances that were retrieved. Both precision \n",
    "   and recall are therefore based on relevance.\n",
    "             Recall = TP/(TP+FN)\n",
    "   \n",
    "where, TP is true positive, FP is false positive, FN is false negative.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f574f9-1a3e-4217-b8c1-36a969c0e367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Confusion Metrics\\nFrom our confusion matrix, we can calculate five different metrics measuring the validity of our model.\\n\\n1. Accuracy (all correct / all) = TP + TN / TP + TN + FP + FN\\n2. Misclassification (all incorrect / all) = FP + FN / TP + TN + FP + FN\\n3. Precision (true positives / predicted positives) = TP / TP + FP\\n4. Sensitivity aka Recall (true positives / all actual positives) = TP / TP + FN\\n5. Specificity (true negatives / all actual negatives) =TN / TN + FP\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''Confusion Metrics\n",
    "From our confusion matrix, we can calculate five different metrics measuring the validity of our model.\n",
    "\n",
    "1. Accuracy (all correct / all) = TP + TN / TP + TN + FP + FN\n",
    "2. Misclassification (all incorrect / all) = FP + FN / TP + TN + FP + FN\n",
    "3. Precision (true positives / predicted positives) = TP / TP + FP\n",
    "4. Sensitivity aka Recall (true positives / all actual positives) = TP / TP + FN\n",
    "5. Specificity (true negatives / all actual negatives) =TN / TN + FP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c2c844-598e-4e4e-8f37-7e9ba4c3e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Confusion matrices can be used to calculate performance metrics for classification models. Of the many performance \\n   metrics used, the most common are accuracy, precision, recall, and F-beta score.\\n   \\n   Accuracy (all correct / all) = TP + TN / TP + TN + FP + FN\\n   Precision (true positives / predicted positives) = TP / TP + FP\\n   Recall (true positives / all actual positives) = TP / TP + FN\\n   Specificity (true negatives / all actual negatives) =TN / TN + FP\\n   F- beta score = (1+beta^2)(Precision*Recall) / (Precision + Recall)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''Confusion matrices can be used to calculate performance metrics for classification models. Of the many performance \n",
    "   metrics used, the most common are accuracy, precision, recall, and F-beta score.\n",
    "   \n",
    "   Accuracy (all correct / all) = TP + TN / TP + TN + FP + FN\n",
    "   Precision (true positives / predicted positives) = TP / TP + FP\n",
    "   Recall (true positives / all actual positives) = TP / TP + FN\n",
    "   Specificity (true negatives / all actual negatives) =TN / TN + FP\n",
    "   F- beta score = (1+beta^2)(Precision*Recall) / (Precision + Recall)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6325881b-01ff-4a3e-be9e-e585e6542bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are some of the most common performance measures you can use from the confusion matrix. Accuracy: It gives you \\n   the overall accuracy of the model, meaning the fraction of the total samples that were correctly classified by the \\n   classifier.\\n   To calculate accuracy, use the following formula:\\n              accuracy = (TP+TN)/(TP+TN+FP+FN)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "'''Here are some of the most common performance measures you can use from the confusion matrix. Accuracy: It gives you \n",
    "   the overall accuracy of the model, meaning the fraction of the total samples that were correctly classified by the \n",
    "   classifier.\n",
    "   To calculate accuracy, use the following formula:\n",
    "              accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82fa8084-d5a3-461b-a68d-fbec1f4eefa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also \\n   use the information in it to calculate measures that can help you determine the usefulness of the model. Rows \\n   represent predicted classifications, while columns represent the true classes from the data.\\n    Confusion Matrix is a performance measurement for the machine learning classification problems where the output\\n    can be two or more classes. It is a table with combinations of predicted and actual values.\\n  A confusion matrix presents a table layout of the different outcomes of the prediction and results of a classification\\n  problem and helps visualize its outcomes. It plots a table of all the predicted and actual values of a classifier.\\n  '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10\n",
    "'''A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also \n",
    "   use the information in it to calculate measures that can help you determine the usefulness of the model. Rows \n",
    "   represent predicted classifications, while columns represent the true classes from the data.\n",
    "    Confusion Matrix is a performance measurement for the machine learning classification problems where the output\n",
    "    can be two or more classes. It is a table with combinations of predicted and actual values.\n",
    "  A confusion matrix presents a table layout of the different outcomes of the prediction and results of a classification\n",
    "  problem and helps visualize its outcomes. It plots a table of all the predicted and actual values of a classifier.\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e5748-b119-4383-91ef-b6759e46a8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
